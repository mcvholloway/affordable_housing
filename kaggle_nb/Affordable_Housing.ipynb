{"cells":[{"metadata":{},"cell_type":"markdown","source":"There are a couple of dependencies that need to be installed first. Make sure under settings on the toolbar to the right that Internet is switched On. The run the next two cells by using Shift + Enter"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rtree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt install -y python3-rtree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Affordable Housing in Nashville/Davidson County"},{"metadata":{},"cell_type":"markdown","source":"## Part 1: Data Wrangling Basics with pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/pandas-logo/pandas_logo.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The pandas library will be our Swiss Army knife for data analysis. We will be using pandas DataFrames, which are useful for manipulating tabular, nonhomogenous data.\n\nFirst, import the pandas library with the alias pd:"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create our first DataFrame, we need to point pandas to the csv file we want to import and use the `read_csv` method:"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"houses_2009 = pd.read_csv('../input/appraisal-data/2009SINGLEFAMILYSF.txt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now view the first few rows using the `.head()` method. We can also inspect the last few rows using `.tail()`."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"houses_2009.head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can check the dimensions of our DataFrame using `.shape`. This returns a tuple (number of rows, number of columns)."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The method `.info()` gives us more information about each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's look a the column names:"},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can access a column by using `houses_2009[\"<column name>\"]`."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009[\"2009 TOTAL APPR\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's adjust the column names. It is a lot easier to work with columns that do not have spaces or start with a number. This will make using tab-completion easier, and will allow us to access a particular column using `houses_2009.<column_name>`.\n\nThe `map` method allows us to apply a function to all elements of a pandas Series or Index. (A pandas Series is a one-dimensional labeled array. The columns of DataFrames are pandas Series.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def square(x):\n    return x**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"square(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we use the `.map` method on a Series with a chosen function, what is returned is a Series whose elements are the result of applying that function to the elements of the original series."},{"metadata":{"trusted":true},"cell_type":"code","source":"example_series = pd.Series([1,2,3,4,5])\n\nexample_series.map(square)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To accomplish renaming the columns, we can use a **lambda function**. A lambda function is an anonymous function which does not need to be declared ahead of its use.\n\nLambda functions come in handy when you need a function that you are using for one task."},{"metadata":{"trusted":true},"cell_type":"code","source":"example_series.apply(lambda x: x**3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To replace a portion of a string, we can use the `replace` string method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"'example string'.replace('ex', 's')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `.map` with a lambda function to remove the spaces and \"2009\"s from our DataFrame's column names."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_001.py\nhouses_2009.columns = houses_2009.columns.map(lambda x: x.replace(' ', '').replace('2009', ''))\nhouses_2009.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.TOTALAPPR.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though we have seen how to rename the columns of our DataFrame by using `.map`, let's look at another method - using **list comprehensions**.\n\nA list comprehension is a way to create a new list from an existing list (or other iterable) and functions very similarly to a _for_ loop."},{"metadata":{"trusted":true},"cell_type":"code","source":"li = [1,2,3]\n\nnew_li = [x**2 for x in li]\n\nnew_li","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use a list comprehension to rename the columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_002.py\nhouses_2009.columns = [x.replace(' ', '').replace('2009','') for x in houses_2009.columns]\nhouses_2009.columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Read in the 2013 and 2017 files and change the column names in the same way as for the 2009 file."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_003.py\nhouses_2013 = pd.read_csv('../input/appraisal-data/2013SINGLEFAMILYSF.txt')\nhouses_2017 = pd.read_csv('../input/appraisal-data/2017SINGLEFAMILYSF.txt')\nhouses_2013.columns = houses_2013.columns.map(lambda x: x.replace(' ', '').replace('2013', ''))\nhouses_2017.columns = houses_2017.columns.map(lambda x: x.replace(' ', '').replace('2017', ''))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 2: Slicing, Counting, and Basic Plots"},{"metadata":{},"cell_type":"markdown","source":"If we want to see the different entries for a column, we can use the `.unique()` method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressCity.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we just care about how many unique elements there are, we can use `.nunique()` instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressCity.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `.value_counts()` method will give a tally of the entries in a particular column, sorted in descending order by default. For example, let's say we want to get a tally of homes by city."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressCity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `value_counts()` to get a tally of homes by their full address."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_101.py\nhouses_2009.AddressFullAddress.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many addresses are duplicated? To answer this, we can use an inequality to return a Boolean series:"},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressFullAddress.value_counts() > 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Python lets us do arithmetic with Booleans. True = 1 and False = 0:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(houses_2009.AddressFullAddress.value_counts() > 1).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's investigate the most common address, 0 Edmondson Pike. \n\nOne way to filter a pandas DataFrame is to slice it using `.loc`. The syntax will look like `houses_2009.loc[<boolean array>]` where the boolean array has the same length as our DataFrame. This will result in a DataFrame containing the rows corresponding to the Trues from the array.\n\nFor example, let's find all homes in Brentwood. Start by creating a boolean array."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressCity == 'BRENTWOOD'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, use `.loc`."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.loc[houses_2009.AddressCity == 'BRENTWOOD']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a boolean array that indicates whether the address in a particular row is equal to 0 Edmondson Pike. Then use this to slice the `houses_2009` DataFrame. How many times does 0 Edmondson Pike appear in the 2009 DataFrame?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_102.py\nedmondson_df = houses_2009.loc[houses_2009.AddressFullAddress == \"0 EDMONDSON PIKE\"]\nedmondson_df.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `.loc` to determine how many times O EDMONDSON PIKE appears in the 2013 and 2017 datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_103.py\nprint(houses_2013.loc[houses_2013.AddressFullAddress == \"0 EDMONDSON PIKE\"].shape)\nprint(houses_2017.loc[houses_2017.AddressFullAddress == \"0 EDMONDSON PIKE\"].shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Harder Exercise:** How many homes in our 2009 dataset have house number 0?  \nHint: To use string methods on columns of DataFrames which are strings, access that column and then use .str. For example, try `houses_2009.AddressCity.str.lower()`"},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.AddressCity.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_104.py\nprint(houses_2009.loc[houses_2009.AddressFullAddress.str[:2] == '0 '].AddressFullAddress.nunique())\nhouses_2009.loc[houses_2009.AddressFullAddress.str[:2] == '0 '].AddressFullAddress.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is not clear what is going on with these duplicated addresses, but we need to decide what to do with our duplicate addresses. One option is to drop all duplicates, which can be accomplished using the `.drop_dupliates()` method and specifying that we want to drop based on the `AddressFullAddress` column.\n\n**Warning:** pandas methods don't have side effects, meaning that they won't affect the original DataFrame when we use them. Thus, when we use a method and want the changes to persist, we must save the result back to the DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009 = houses_2009.drop_duplicates('AddressFullAddress')\nhouses_2013 = houses_2013.drop_duplicates('AddressFullAddress')\nhouses_2017 = houses_2017.drop_duplicates('AddressFullAddress')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few more words on `.loc`. We can slice our DataFrame using `.loc` and a boolean series, as before, but we can also use `.loc` to slice by passing which index values we want (row, column, or both). This looks like `df.loc[<rows>,<columns>]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.loc[100:105,['AddressFullAddress', 'AddressCity']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.loc[[1000, 2000, 3000], 'CouncilDistrict']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `.loc` to find the appraised value and the finished area of the house in row 50000."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_105.py\nhouses_2009.loc[50000, ['TOTALAPPR', 'FinishedArea']]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time for some plots! Let's look at the number of single family homes assessed in each district. \n\nPlotting can be done using pandas DataFrame methods. Behind the scenes, this is done using the matplotlib library. In order to get our plots to display in our notebook, we can use the ipython magic command `%matplotlib inline`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.CouncilDistrict.value_counts().plot.bar();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots we create are highly customizable. For a (partial) list of stylistic options, see https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.html."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = houses_2009.CouncilDistrict.value_counts().plot.bar(figsize = (14,6), width = 0.75,\n                                                         rot = 0, color = 'plum')\nfig.set_xlabel('District')\nfig.set_title('Number of Single-Family Homes by District, 2009', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `.plot` method orders the bars in the order they apper in the given DataFrame. If we want to change the order, say in order by district number, we can reorder the rows of our DataFrame by using `.loc`."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.CouncilDistrict.value_counts().loc[list(range(1,36))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = houses_2009.CouncilDistrict.value_counts().loc[list(range(1,36))].plot.bar(figsize = (14,6), width = 0.75,\n                                                         rot = 0, color = 'plum')\nfig.set_xlabel('District')\nfig.set_title('Number of Single-Family Homes by District, 2009', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a bar chart showing the number of single-family homes by zip code for 2009."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_106.py\nfig = houses_2009.AddressPostalCode.value_counts().plot.bar(figsize = (14,6),\n                                                         rot = 40, color = 'plum', width = 0.8)\nfig.set_xlabel('Zip Code')\nfig.set_title('Number of Single-Family Homes by Zip Code, 2009', fontweight = 'bold');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we want to display the distribution of a variable, we can use a histogram. For example, let's say we want to look at the distribution of square footages."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = houses_2009.FinishedArea.plot.hist(figsize = (10,4))\nfig.set_title('Distribution of Homes by Square Footage', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get some extreme square footages - let's investigate."},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Determine the number of homes in the `houses_2009` DataFrame that have finished area of at least 15,000 sqft. Which district contains the most number of these homes?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_107.py\nprint(len(houses_2009.loc[houses_2009.FinishedArea >= 15000]))\nhouses_2009.loc[houses_2009.FinishedArea >= 15000].CouncilDistrict.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's narrow down the dataset we use in order to get a more informative histogram. Notice too that we can adjust the number of bins to further imporve the histogram."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.loc[houses_2009.FinishedArea < 10000].FinishedArea.plot.hist(figsize = (10,4), bins = 50)\nplt.title('Distribution of Homes by Square Footage', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also put two histograms on the same plot in order to compare two distributions. Let's say we want to compare the distribution of appraisal values from 2009 to 2017."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.TOTALAPPR.plot.hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to determine a good cutoff, we can use the `.describe()` method which gives summary statistics on our DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.TOTALAPPR.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 75% of homes are appraised at \\$220,000 or less."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.loc[houses_2009.TOTALAPPR <= 750000].TOTALAPPR.plot.hist(bins = 50);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With two histograms, we should set the alpha values lower to increase the transparency. It is also probably a good idea to normalize our histograms so they they are showing densities rather than counts."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = houses_2009.loc[houses_2009.TOTALAPPR <= 750000].TOTALAPPR.plot.hist(bins = 50, alpha = 0.6, density = True, label = '2009', figsize = (10,5))\nhouses_2017.loc[houses_2017.TOTALAPPR <= 750000].TOTALAPPR.plot.hist(bins = 50, alpha = 0.6, density = True, label = '2013');\nfig.axes.get_yaxis().set_visible(False)\nfig.set_title('Distribution of Appraisal Values, 2009 vs 2013')\nfig.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a histograms showing distributions of appraisal values for homes in Madison and for homes in Brentwood. Plot both on the same figure."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_108.py\nfig = houses_2009.loc[houses_2009.AddressCity == 'MADISON'].TOTALAPPR.plot.hist(bins = 40, figsize = (10,6), alpha = 0.4, density = True, color='blue', label = 'Madison', \n                                                                          legend = True, title = 'Distribution of Appraisal Values, 2009')\nhouses_2009.loc[houses_2009.AddressCity == 'BRENTWOOD'].TOTALAPPR.plot.hist(bins = 120, figsize = (10,6), alpha = 0.4, density = True, color='red', label = 'Brentwood', legend = True)\nfig.axes.get_yaxis().set_visible(False);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Harder Exercise:** Show only homes with appraisal values less than $1,000,000.\nHint: To slice a DataFrame with `.loc` using multiple boolean series, separate the series with & for AND or | for OR. For example, to find all homes in Antioch that are at least 4,000 square feet, you can use `houses_2009.loc[(houses_2009.AddressCity == \"ANTIOCH\") & (houses_2009.FinishedArea >= 4000)]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_109.py\nfig = houses_2009.loc[(houses_2009.AddressCity == 'MADISON') & (houses_2009.TOTALAPPR < 1000000)].TOTALAPPR.plot.hist(bins = 40, figsize = (10,6), alpha = 0.4, density = True, color='blue', label = 'Madison', legend = True, title = 'Distribution of Appraisal Values, 2009')\nhouses_2009.loc[(houses_2009.AddressCity == 'BRENTWOOD') & (houses_2009.TOTALAPPR < 1000000)].TOTALAPPR.plot.hist(bins = 40, figsize = (10,6), alpha = 0.4, density = True, color='red', label = 'Brentwood', legend = True)\nfig.axes.get_yaxis().set_visible(False);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## `groupby` to Aggregate by Category\n\npandas makes it easy to calculate statistics by category. First, we need to specify the column or columns we want to group by and then we specify how we cant to calculate our summary statistics."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.groupby('CouncilDistrict').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how it returns a count for each column. We can instead choose a single column."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.groupby('CouncilDistrict').APN.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.groupby('CouncilDistrict').TOTALAPPR.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also apply multiple aggregate functions by using the `.agg` method after applying `.groupby`."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.groupby('CouncilDistrict').TOTALAPPR.agg(['mean', 'median'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also aggregate multiple columns by passing a _dictionary_ to `.agg()`.\n\nA python dictionary consists of key-value pairs. We can create a dictionary by enclosing the key-value pairs in squiggly brackets { }.\n\nTo aggregate on multiple columns, we pass a dictionary whose keys are the columns we wish to aggregate and whose values are the aggregation functions we want to use."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.groupby('CouncilDistrict').agg({'TOTALAPPR':['mean', 'median'], 'FinishedArea': ['mean', 'median']})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how the column labels look different now. That is because when doing multiple aggregations the resulting DataFrame will now have a _MultiIndex_. It is also possible to have a row MultiIndex."},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df = houses_2009.groupby('CouncilDistrict').agg({'TOTALAPPR':['mean', 'median'], 'FinishedArea': ['mean', 'median']})\nagg_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also get a MultiIndex by grouping by multiple columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df = houses_2009.groupby(['CouncilDistrict', 'AddressPostalCode']).TOTALAPPR.median()\nagg_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To access entries, we can pass tuples."},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df.loc[25]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df.loc[(25, 37205)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a plot showing the median appraisal value by district for 2009."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_110.py\nfig = houses_2009.groupby('CouncilDistrict').TOTALAPPR.median().loc[list(range(1,36))].plot.bar(figsize = (14,6), width = 0.75,\n                                                         rot = 0, color = 'plum')\nfig.set_xlabel('District')\nfig.set_title('Median Appraisal Value, 2009', fontweight = 'bold');\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we have two metrics we want to compare on the same plot, we can use the `twinx()` method to have two different vertical scales."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,5))\nax2 = ax.twinx()\n\nwidth = 0.4\n\nhouses_2009.groupby('CouncilDistrict').TOTALAPPR.mean().plot.bar(color='plum', ax=ax, width=width, position=1, edgecolor = 'black', rot = 0)\nhouses_2009.groupby('CouncilDistrict').FinishedArea.mean().plot.bar(color='lightcoral', ax=ax2, width=width, position=0, edgecolor= 'black')\n\nax.set_ylabel('Median Appraisal Value')\nax2.set_ylabel('Average Square Footage')\n\nplt.xlim(-1,35)\nplt.title('Housing Snapshot by District, 2009', fontweight = 'bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS = pd.read_csv('../input/census/ACS.csv')\nACS = ACS.set_index('district')\nACS.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** the ACS.csv file contains the number of households and the median household income by council district, obtained from the US Census Bureau's American Community Survey. Create a side-by-side bar plot comparing median income by district to median home price in 2017."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_111.py\nfig, ax = plt.subplots(figsize = (12,5))\nax2 = ax.twinx()\n\nwidth = 0.4\n\nACS.loc[ACS.year == 2017].median_income.plot.bar(color='plum', ax=ax, width=width, position=1, edgecolor = 'black', rot = 0)\nhouses_2017.groupby('CouncilDistrict').TOTALAPPR.median().plot.bar(color='lightcoral', ax=ax2, width=width, position=0, edgecolor= 'black')\n\nax.set_ylabel('Median Income')\nax2.set_ylabel('Median Appraisal Value')\nplt.xticks(rotation = 90)\nplt.xlim(-1,35)\n\nplt.title('Housing Snapshot by District, 2017', fontweight = 'bold');\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A bar plot is not necessarily the best way to display this data. Perhaps a scatter plot might be easier to read."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,6))\nplt.scatter(x = ACS.loc[ACS.year == 2017].median_income, \n         y = houses_2017.groupby('CouncilDistrict').TOTALAPPR.median(),\n           alpha = 0.75)\nplt.xlabel('Median Income')\nplt.ylabel('Median Household Appraisal Value');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our plot would be a lot more useful if we knew which district corresponded to each point. \n\nTo add our labels, we can use the matplotlib `annotate` function. We need to specify the text that we want (using the `s` parameter) and where we want to place the text (using the `xy` parameter)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,6))\nplt.scatter(x = ACS.loc[ACS.year == 2017].median_income, \n         y = houses_2017.groupby('CouncilDistrict').TOTALAPPR.median(),\n           alpha = 0.75)\nplt.xlabel('Median Income')\nplt.ylabel('Median Household Appraisal Value')\nfor i in range(1,36):\n    plt.annotate(xy = (ACS.loc[ACS.year == 2017].median_income.loc[i], houses_2017.groupby('CouncilDistrict').TOTALAPPR.median().loc[i]),\n                s = str(i));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 3: Introduction to GeoPandas"},{"metadata":{},"cell_type":"markdown","source":"Let's create a map of these districts so we can get a better idea of where the supply of single-family homes is located.  \n\nWe will be using the geopandas library, which provides tools for working with geospatial data."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import geopandas as gpd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to load in a shape file that includes the boundaries for the council districts. We will be using a geojson file obtained from https://data.nashville.gov/General-Government/Council-District-Outlines-GIS-/m4q4-q7tc"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts = gpd.read_file('../input/shapefiles/Council_District_Outlines.geojson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"council_districts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can plot the council districts by calling `.plot()` on the GeoDataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"council_districts.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To adjust the size of our plot, we can call `plt.subplots()` and specify the figsize. The matplotlib `subplots` function creates a matplotlib figure and axis. We need to specify that we want to create our plot on the axis that we created."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we want to label these districts? To do this, we'll need coordinates for the center of each district. The shapely library provides a `representative_point()` method which will, given a (multi)polygon, return a point within that polygon. We can use this method on the geometry column of our DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"council_districts.loc[0, 'geometry']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(council_districts.loc[0, 'geometry'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"council_districts.loc[0, 'geometry'].representative_point()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(council_districts.loc[0, 'geometry'].representative_point())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(council_districts.loc[0, 'geometry'].representative_point().coords)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use map and a lambda function to extract the representative point for each district. Save this as a new column called \"coords\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_201.py\ncouncil_districts['coords'] = council_districts.geometry.map(lambda x: x.representative_point().coords[:][0])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to add a label onto our map for each row in the dataset.\n\nOne way to access the rows in a dataframe one at a time is by using the `.iterrows()`, method, which produces a generator object. This is an object that we can iterate through. We can call `next()` on a generator object in order to iterate through its contents."},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = council_districts.iterrows()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(rows)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we call `next` we get a tuple which gives the index of the row and its values. We can unpack this tuple to extract what we want:"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx, row = next(rows)\nprint(idx)\nprint(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row['district']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also iterate through all of the rows using a `for` loop:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, row in rows:\n    print(row['district'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `.iterrows()` along with `plt.annotate` to add district makers to our plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_203.py\nfig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax)\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Link to more detailed map: http://maps.nashville.gov/webimages/MapGallery/PDFMaps/2018%20Council%20Members.pdf"},{"metadata":{},"cell_type":"markdown","source":"Some of these labels are in a less than ideal location. Look at, for example, District 11 on the northeast part of town.  \nTo correct these, we can write a helper function to nudge those points into a slightly better location."},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift_coord(district, amount, direction):\n    old_coord = council_districts.loc[council_districts.district == district, 'coords'].values[0]\n    if direction == 'up':\n        new_coord = (old_coord[0], old_coord[1] + amount)\n    if direction == 'down':\n        new_coord = (old_coord[0], old_coord[1] - amount)\n    if direction == 'left':\n        new_coord = (old_coord[0] - amount, old_coord[1])\n    if direction == 'right':\n        new_coord = (old_coord[0] + amount, old_coord[1])\n    council_districts.loc[council_districts.district == district, 'lng'] = new_coord[0]\n    council_districts.loc[council_districts.district == district, 'lat'] = new_coord[1]\n\n    council_districts.loc[council_districts.district == district, 'coords'] = council_districts.loc[council_districts.district == district, ['lng', 'lat']].apply(tuple, axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shift_coord(district='15', amount = 0.005, direction = 'left')\nshift_coord(district='9', amount = 0.005, direction = 'down')\nshift_coord(district='15', amount = 0.02, direction = 'down')\nshift_coord(district='28', amount = 0.003, direction = 'down')\nshift_coord(district='6', amount = 0.005, direction = 'down')\nshift_coord(district='27', amount = 0.004, direction = 'left')\nshift_coord(district='27', amount = 0.005, direction = 'down')\nshift_coord(district='11', amount = 0.01, direction = 'down')\nshift_coord(district='18', amount = 0.005, direction = 'down')\nshift_coord(district='22', amount = 0.01, direction = 'down')\nshift_coord(district='25', amount = 0.006, direction = 'down')\nshift_coord(district='21', amount = 0.005, direction = 'right')\nshift_coord(district='24', amount = 0.005, direction = 'right')\nshift_coord(district='3', amount = 0.01, direction = 'down')\nshift_coord(district='3', amount = 0.005, direction = 'left')\nshift_coord(district='7', amount = 0.015, direction = 'down')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax)\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to combine this data frame with the number of homes per district."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"homes_per_district = houses_2009.CouncilDistrict.value_counts()\nhomes_per_district","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(homes_per_district)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just using the `.value_counts()` method returns a pandas Series. We can turn in into a DataFrame by using `.reset_index()` on it."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"homes_per_district = homes_per_district.reset_index()\nhomes_per_district.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can merge the counts with our council districts DataFrame. To make this easier, we can rename the columns so that the columns containing the district numbers match."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"homes_per_district.columns = ['district', 'num_homes_2009']\nhomes_per_district.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can use the pandas merge function. We need to specify the two DataFrames we with to merge using the `left` and `right` arguments. If we don't tell it otherwise, it will attempt to merge on all columns that appear in both dataframes (in our case, the `district` column)."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"pd.merge(left = council_districts, right = homes_per_district)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oops - we get an error. Pandas won't let us merge columns with different types. We can change the data type of the district column using the `astype` method. This will then allow us to merge the two dataframes."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts.district = council_districts.district.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts = pd.merge(left = council_districts, right = homes_per_district)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    After the merge, `council_districts` remains a GeoDataFrame."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"type(council_districts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we call .plot() on a GeoDataFrame, we can create a choropleth by specifying `column = <column_name>`. Here, we will color by number of homes."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009')\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can add a legend explaining the meaning of the colors by specifying `legend = True`."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', legend = True)\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This colormap is not necessarily the best. We can speciy a different one using the cmap argument. \n\nSee https://matplotlib.org/tutorials/colors/colormaps.html to see the colormap options. \n\nIf you don't like any of those, it is also possible to create you own (but it takes some work to do so)."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', legend = True, cmap = 'YlOrRd',edgecolor = 'grey')\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We end up with an oddly-sized colormap. To modify it, we can use a couple of helper tools; namely, `make_axes_locatable` and `cm`."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from matplotlib import cm\nfrom matplotlib.colors import Normalize\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\n\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', cmap = 'YlOrRd', edgecolor = 'grey')\n\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold', color = 'black')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(council_districts.num_homes_2009.min(), council_districts.num_homes_2009.max()), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make it more readable, let's create another helper function that will adjust the color of the district label based on its background.\n\n**Exercise:** Write a function called `choose_color` which returns 'black' if its input is less than 5000 and returns 'white' otherwise. Then adjust the above code to use your function to set the label colors."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_202.py\ndef choose_color(num_homes):\n    if num_homes < 5000: return \"black\"\n    return \"white\"\n\nfig, ax = plt.subplots(figsize = (10,10))\n\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', cmap = 'YlOrRd', edgecolor = 'grey')\n\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold', \n                 color = choose_color(row['num_homes_2009']))\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(council_districts.num_homes_2009.min(), council_districts.num_homes_2009.max()), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just a few more adjustments. We can add a title using `plt.title`. Within this function, we can also specify the font size and make the text bold.  \n\nSecond, since they are not really all that informative in this case, we might as well remove the axes by using `plt.axis('off')`."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\n\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', cmap = 'YlOrRd', edgecolor = 'grey')\n\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold', color = choose_color(row['num_homes_2009']))\n\nplt.title('Number of Single-Family Homes by Council District, 2009', fontweight = 'bold', fontsize = 14)\nplt.axis('off')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(council_districts.num_homes_2009.min(), council_districts.num_homes_2009.max()), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding Interstates"},{"metadata":{},"cell_type":"markdown","source":"So far, we have seen geometric objects in the form of (multi)polygons and points, but there are also lines.  \n\nWe can make our map a little easier to read by adding interstates. We will be using a shapefile of major roads obtained from https://catalog.data.gov/dataset/tiger-line-shapefile-2016-nation-u-s-primary-roads-national-shapefile/resource/94e763bb-78a9-48bb-8759-2c5c98508636."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"interstates = gpd.read_file('../input/shapefiles/tl_2016_us_primaryroads.shp')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"interstates.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"interstates.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GeoDataFrames come equipped with a coordinate reference system, or crs. These have to do with the particular projection used to create the geometries."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(interstates.crs)\nprint(council_districts.crs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how the two GeoDataFrames we are using have different coordinate reference systems. We need to fix this by converting using the `to_crs()` method."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"interstates = interstates.to_crs(council_districts.crs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can narrow our interstates GeoDataFrame down to just those that intersect the council districts, using a spatial join. We'll keep only those highway segments that intersect the council districts."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"interstates = gpd.sjoin(interstates, council_districts, how=\"inner\", op='intersects')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax)\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')\ninterstates.plot(color = 'black', ax = ax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how the segment of I-40 extends further east than we need. We can fix this by specifying the x and y limits. The matplotlib functions `.xlim` and `.ylim` will either return the current values for the x and y range or can be used to specify new limits. Here, we will use them twice: once to get the limits before we plot the interstates and then again to reset the limits after plotting them."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\ncouncil_districts.plot(ax = ax)\nxlims = plt.xlim()\nylims = plt.ylim()\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')\ninterstates.plot(color = 'black', ax = ax)\nplt.xlim(xlims)\nplt.ylim(ylims);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can combine this with our previous plot."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,10))\n\ncouncil_districts.plot(ax = ax, column = 'num_homes_2009', cmap = 'YlOrRd', edgecolor = 'grey')\n\nxlims = plt.xlim()\nylims = plt.ylim()\n\ninterstates.plot(color = 'black', ax = ax)\nplt.xlim(xlims)\nplt.ylim(ylims)\n\n\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold', color = choose_color(row['num_homes_2009']))\n\nplt.title('Number of Single-Family Homes by Council District, 2009', fontweight = 'bold', fontsize = 14)\nplt.axis('off')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(council_districts.num_homes_2009.min(), council_districts.num_homes_2009.max()), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a choropleth showing the average square footage per district in 2009.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_204.py\ncouncil_districts = pd.merge(left = council_districts, right = houses_2009.groupby('CouncilDistrict').FinishedArea.mean().reset_index().rename(columns = {'CouncilDistrict': 'district'}))\n\ndef choose_color_sf(area):\n    if area > 2500: return 'white'\n    return 'black'\n\nfig, ax = plt.subplots(figsize = (10,10))\n\ncouncil_districts.plot(ax = ax, column = 'FinishedArea', cmap = 'YlOrRd', edgecolor = 'grey')\nxlims = plt.xlim()\nylims = plt.ylim()\ninterstates.plot(color = 'black', ax = ax)\nplt.xlim(xlims)\nplt.ylim(ylims)\nfor idx, row in council_districts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold', color = choose_color_sf(row['FinishedArea']))\n\nplt.title('Average Square Footage by Council District, 2009', fontweight = 'bold', fontsize = 14)\nplt.axis('off')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(council_districts.FinishedArea.min(), council_districts.FinishedArea.max()), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 4: Adding Interactivity with ipywidgets"},{"metadata":{},"cell_type":"markdown","source":"What if we want to see how this changes over time?"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"homes_per_district_2013 = pd.DataFrame(houses_2013.CouncilDistrict.value_counts().sort_values()).reset_index()\nhomes_per_district_2013.columns = ['district', 'num_homes_2013']\n\nhomes_per_district_2017 = pd.DataFrame(houses_2017.CouncilDistrict.value_counts().sort_values()).reset_index()\nhomes_per_district_2017.columns = ['district', 'num_homes_2017']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Merge homes_per_district_2013 and homes_per_district_2017 into the council_districts DataFrame.  \nHint: you may either have to do this in two steps or to use nested calls."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_301.py\ncouncil_districts = pd.merge(left = pd.merge(left = council_districts, right = homes_per_district_2013), right = homes_per_district_2017)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a function named `generate_map` which takes as input a year and produces a plot of number of homes per district for that year."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_302.py\ndef generate_map(year):\n    year = str(year)\n    fig, ax = plt.subplots(figsize = (10,10))\n    column = 'num_homes_' + year\n    \n    council_districts.plot(ax = ax, column = column, cmap = 'YlOrRd', edgecolor = 'grey')\n    \n    xlims = plt.xlim()\n    ylims = plt.ylim()\n    interstates.plot(color = 'black', ax = ax)\n    plt.xlim(xlims)\n    plt.ylim(ylims)\n\n    for idx, row in council_districts.iterrows():\n        plt.annotate(s=row['district'], xy=row['coords'],\n                     horizontalalignment='center', fontweight = 'bold', color = choose_color(row[column]))\n\n    plt.title(f'Number of Single-Family Homes by Council District, {year}', fontweight = 'bold', fontsize = 14)\n    plt.axis('off')\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\n    cmap = cm.ScalarMappable(\n          norm = Normalize(council_districts[column].min(), council_districts[column].max()), \n          cmap = 'YlOrRd')\n    cmap.set_array([])    \n    fig.colorbar(mappable=cmap, cax = cax); \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_map(2013)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having a function to generate the map is great, but what if we didn't want to change the input parameter and rerun the cell each time we want to view a different year. Also, wouldn't it be nice to only be able to choose years for which we have data? We can accomplish this by using the `ipywidgets` library to create interactive plots."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from ipywidgets import interact","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### `interact` as a function:\n\nOne way to use `interact` is as a function that takes as input other functions. It takes as arguments a function followed by one or more keyword arguments. These arguments should be the input variables to the passed function. \n\nFor example, let's create an interactive widget using the squaring function. First, we need to define our function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def square(x):\n    return x**2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, pass our function in as the first argument to interact. We want to be able to modify the input variable, `x`, so we also need to specify that as an argument with a default value."},{"metadata":{"trusted":true},"cell_type":"code","source":"interact(square, x = 5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also create interactive widgets for functions with more than one argument:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sum_squares(x,y):\n    return x**2 + y**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interact(sum_squares, x = 5, y = 5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't just have to return values - we can also create plots:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_power_function(k):\n    xs = range(50)\n    dynamic_ys = [x ** k for x in xs]\n    plt.plot(xs, dynamic_ys)\n\ninteract(plot_power_function, k = [1/4,1/3,1/2,1,2,3,4]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Make the generate_map function interactive, allowing the user to select the year they want to plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_303.py\n@interact(year = ['2009', '2013', '2017'])\ndef generate_map(year):\n    fig, ax = plt.subplots(figsize = (10,10))\n    column = 'num_homes_' + year\n    \n\n    council_districts.plot(ax = ax, column = column, cmap = 'YlOrRd', edgecolor = 'grey')\n    \n    xlims = plt.xlim()\n    ylims = plt.ylim()\n    interstates.plot(color = 'black', ax = ax)\n    plt.xlim(xlims)\n    plt.ylim(ylims)\n\n    for idx, row in council_districts.iterrows():\n        plt.annotate(s=row['district'], xy=row['coords'],\n                     horizontalalignment='center', fontweight = 'bold', color = choose_color(row[column]))\n\n    plt.title(f'Number of Single-Family Homes by Council District, {year}', fontweight = 'bold', fontsize = 14)\n    plt.axis('off')\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\n    cmap = cm.ScalarMappable(\n          norm = Normalize(council_districts[column].min(), council_districts[column].max()), \n          cmap = 'YlOrRd')\n    cmap.set_array([])    \n    fig.colorbar(mappable=cmap, cax = cax);   \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is pretty good, but notice how the colorscale changes across years. To make it easier to compare, it would be useful to have a fixed colorscale. To accomplish this, we can add the vmin and vmax arguments. Also, we need to redefine our choose_color function to accomodate the expanded colorscale."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def choose_color_scaled(num_homes, vmin, vmax):\n    if num_homes < (vmin + vmax) / 2: return \"black\"\n    return \"white\"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"vmin = council_districts[['num_homes_2009', 'num_homes_2013', 'num_homes_2017']].values.min()\nvmax = council_districts[['num_homes_2009', 'num_homes_2013', 'num_homes_2017']].values.max()\n\n@interact(year = ['2009', '2013', '2017'])\ndef generate_map(year):\n    fig, ax = plt.subplots(figsize = (10,10))\n    column = 'num_homes_' + year\n    \n\n    council_districts.plot(ax = ax, column = column, cmap = 'YlOrRd', edgecolor = 'grey', vmin = vmin, vmax = vmax)\n\n    xlims = plt.xlim()\n    ylims = plt.ylim()\n    interstates.plot(color = 'black', ax = ax)\n    plt.xlim(xlims)\n    plt.ylim(ylims)\n    \n    for idx, row in council_districts.iterrows():\n        plt.annotate(s=row['district'], xy=row['coords'],\n                     horizontalalignment='center', fontweight = 'bold', color = choose_color_scaled(row[column], vmin, vmax))\n\n    plt.title(f'Number of Single-Family Homes by Council District, {year}', fontweight = 'bold', fontsize = 14)\n    plt.axis('off')\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\n    cmap = cm.ScalarMappable(\n          norm = Normalize(vmin, vmax), \n          cmap = 'YlOrRd')\n    cmap.set_array([])    \n    fig.colorbar(mappable=cmap, cax = cax);   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing changes in single-family housing supply"},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create two new columns in the council_districts DataFrame, calculating the absolute and relative change in number of single-family homes from 2009 to 2017. Call these columns `absolute_change` and `relative_change`."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_304.py\ncouncil_districts['absolute_change'] = council_districts.num_homes_2017 - council_districts.num_homes_2009\ncouncil_districts['relative_change'] = 100 * council_districts.absolute_change / council_districts.num_homes_2009\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can find the districts which had the largest and smallest change in housing supply by using the `sort_values()` method."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts[['district', 'absolute_change']].sort_values('absolute_change').head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts[['district', 'absolute_change']].sort_values('absolute_change', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"council_districts[['district', 'relative_change']].sort_values('relative_change', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create an interactive plot showing absolute and relative change in the number of single-family homes by district."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_305.py\n@interact(type = ['absolute', 'relative'])\ndef generate_map(type):\n    fig, ax = plt.subplots(figsize = (10,10))\n    column = type + '_change'\n    \n    council_districts.plot(ax = ax, column = column, cmap = 'YlOrRd', edgecolor = 'grey')\n\n    xlims = plt.xlim()\n    ylims = plt.ylim()\n    \n    interstates.plot(color = 'black', ax = ax)\n    plt.xlim(xlims)\n    plt.ylim(ylims)\n    \n    vmin = council_districts[column].min()\n    vmax = council_districts[column].max()\n    \n    for idx, row in council_districts.iterrows():\n        plt.annotate(s=row['district'], xy=row['coords'],\n                     horizontalalignment='center', fontweight = 'bold', color = choose_color_scaled(row[column], vmin, vmax))\n\n    plt.title(type[0].upper() + type[1:] + ' Change in Number of Single-Family Homes, 2009-2017', fontweight = 'bold', fontsize = 14)\n    plt.axis('off')\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\n    cmap = cm.ScalarMappable(\n          norm = Normalize(vmin, vmax), \n          cmap = 'YlOrRd')\n    cmap.set_array([])    \n    fig.colorbar(mappable=cmap, cax = cax);   \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 6: Appraisal Values"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"houses_2017.TOTALAPPR.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some very expensive homes in our dataset. One home appraises for over $11 million! Let's see where these very expensive homes are.\n\n**Exercise:** Create a dataframe called `million_dollar_homes` which contains all homes which were appraised at least $1 million in 2017."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your Code Here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %load ../input/exercisesolutions/soln_306.py\nmillion_dollar_homes = houses_2017.loc[houses_2017.TOTALAPPR >= 1000000]\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(million_dollar_homes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"million_dollar_homes.CouncilDistrict.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's merge the million dollar homes count with our `council_districts` DataFrame and same the result to a DataFrame called `million_dollar_counts`."},{"metadata":{"trusted":true},"cell_type":"code","source":"million_dollar_counts = pd.merge(council_districts[['district', 'geometry', 'coords']],\n         million_dollar_homes.CouncilDistrict.value_counts().reset_index().rename(columns = {'index': 'district', 'CouncilDistrict' : 'num_homes'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vmin = million_dollar_counts.num_homes.min()\nvmax = million_dollar_counts.num_homes.max()\n\nfig, ax = plt.subplots(figsize = (10,10))\n\nmillion_dollar_counts.plot(ax = ax, column = 'num_homes', cmap = 'YlOrRd', edgecolor = 'grey', \n                           vmin = vmin, vmax = vmax)\n\nxlims = plt.xlim()\nylims = plt.ylim()\n\ninterstates.plot(color = 'black', ax = ax)\nplt.xlim(xlims)\nplt.ylim(ylims)\n\nfor idx, row in million_dollar_counts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')\n\nplt.title('Number of Million-Dollar Homes by Council District', fontweight = 'bold', fontsize = 14)\nplt.axis('off')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(vmin, vmax), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What about those districts not showing up? They are districts with no million dollar homes. When we call `.value_counts()`, they don't appear since they didn't appear in our `million_dollar_homes` DataFrame. We can remedy this be changing the type of merge we use to an outer merge. To specify the type of merge, we can use the `how` argument."},{"metadata":{"trusted":true},"cell_type":"code","source":"million_dollar_counts = pd.merge(council_districts[['district', 'geometry', 'coords']],\n         million_dollar_homes.CouncilDistrict.value_counts().reset_index().rename(columns = {'index': 'district', 'CouncilDistrict' : 'num_homes'}),\n        how = 'outer')\nmillion_dollar_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To correct the NaNs, we can use the `.fillna()` method and specify that we want to fill missing values with 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"million_dollar_counts = million_dollar_counts.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vmin = million_dollar_counts.num_homes.min()\nvmax = million_dollar_counts.num_homes.max()\n\nfig, ax = plt.subplots(figsize = (10,10))\n\nmillion_dollar_counts.plot(ax = ax, column = 'num_homes', cmap = 'YlOrRd', edgecolor = 'grey', vmin = vmin, vmax = vmax)\n\nxlims = plt.xlim()\nylims = plt.ylim()\n\ninterstates.plot(color = 'black', ax = ax)\nplt.xlim(xlims)\nplt.ylim(ylims)\n\nfor idx, row in million_dollar_counts.iterrows():\n    plt.annotate(s=row['district'], xy=row['coords'],\n                 horizontalalignment='center', fontweight = 'bold')\n\nplt.title('Number of Million-Dollar Homes by Council District', fontweight = 'bold', fontsize = 14)\nplt.axis('off')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n\ncmap = cm.ScalarMappable(\n      norm = Normalize(vmin, vmax), \n      cmap = 'YlOrRd')\ncmap.set_array([])    \nfig.colorbar(mappable=cmap, cax = cax);   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Where are the 5 most expensive houses? To answer this, we can use the `.nlargest()` method."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2017.nlargest(n=5, columns='TOTALAPPR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's try to see what the supply of affordable housing looks like. To do this, we will adopt HUD's definitions of \"affordable\" and \"workforce\" housing, which is based on the Area Median Income. See https://www.hud.gov/program_offices/comm_planning/affordablehousing/ "},{"metadata":{},"cell_type":"markdown","source":"Area Median Income for Davidson County: \n\n    2009: $64,900  \n    \n    2013: $62,300  \n    \n    2017: $68,000  "},{"metadata":{},"cell_type":"markdown","source":"HUD declares a household to be **cost-burdened** if they are spending more than 30% of their income on housing costs.\n\n**Affordable Housing:** Won't cost-burden households making less than 60% of AMI.\n    \n**Workforce Housing:** Won't cost people making between 60% and 120% of AMI."},{"metadata":{},"cell_type":"markdown","source":"Let's classify these according to whether they are affordable to someone making 30%, 60%, 90%, or 120% of AMI. We will need to estimate the total yearly cost of each house. We can make this estimate based on its appraised value."},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_mortgage_payment(TOTALAPPR,years = 30, rate = 4, down_payment = 20):\n    P = TOTALAPPR * (1 - (down_payment / 100))\n    n = 12 * years\n    r = rate / (100 * 12)\n    M = P * (r * (1 + r)**n) / ((1 + r)**n - 1)\n    return M","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a new column in each DataFrame, called `est_mortgage_cost` that uses the `find_mortgage_payment` function to get a _yearly_ estimated cost."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Your code here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load soln_401.py","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also need to factor in property taxes, which are determined by a houses's district code. The rates can be found at http://www.padctn.org/services/tax-rates-and-calculator/. These rates are applied to the houses's assessed value, which is contained in the `TOTALASSD` column.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tax_rates = {'USD' : 3.155/100,\n            'GSD' : 2.755/100,\n             'GO' : 3.503 / 100,\n             'FH' : 2.755/100,\n             'OH' : 2.755/100,\n             'BM' : 3.012/100,\n             'BH' : 2.755/100,\n            'CBID' : 3.2844 / 100,\n            'GBID': 3.2631 / 100,\n            'RT' : 3.437/100,\n            'LW' : 2.755/100}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_property_taxes(row):\n    return row.TOTALASSD * tax_rates[row.DistrictCode]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009['est_property_tax'] = houses_2009.apply(calculate_property_taxes, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oops! We get an error. It seems that some of the values in the DistrictCode have some extra white space. The string method `.strip()` removes any white space at the beginning or end of a sting. We can apply this to our DistrictCode column to correct the problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009.DistrictCode = houses_2009.DistrictCode.str.strip()\nhouses_2013.DistrictCode = houses_2013.DistrictCode.str.strip()\nhouses_2017.DistrictCode = houses_2017.DistrictCode.str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009['est_property_tax'] = houses_2009.apply(calculate_property_taxes, axis = 1)\nhouses_2013['est_property_tax'] = houses_2013.apply(calculate_property_taxes, axis = 1)\nhouses_2017['est_property_tax'] = houses_2017.apply(calculate_property_taxes, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also need to factor in insurance cost. We'll use \\$60/month, or \\$720/year as our estimate for homeowner's insurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009['est_yearly_cost'] = houses_2009.est_mortgage_cost + houses_2009.est_property_tax + 720\nhouses_2013['est_yearly_cost'] = houses_2013.est_mortgage_cost + houses_2013.est_property_tax + 720\nhouses_2017['est_yearly_cost'] = houses_2017.est_mortgage_cost + houses_2017.est_property_tax + 720","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have an estimated yearly cost, we can put each house into a category. We'll use 5 categories:\n * __AFF_1:__ not cost-burdening to those making 30\\% of AMI\n * __AFF_2:__ not cost-burdening to those making 60\\% of AMI\n * __WF_1:__ not cost-burdening to those making 90\\% of AMI\n * __WF_2:__ not cost-burdening to those making 120% of AMI\n * __AWF:__ Requires more than 120% of AMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify_house(value, AMI):\n    if value <= 0.3 * 0.3*AMI:\n        return 'AFF_1'\n    elif value <= 0.3 * 0.6 * AMI:\n        return 'AFF_2'\n    elif value <= 0.3* 0.9 * AMI:\n        return 'WF_1'\n    elif value <= 0.3 * 1.2*AMI:\n        return 'WF_2'\n    else:\n        return 'AWF'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009['category'] = houses_2009.est_yearly_cost.apply(lambda x: classify_house(x, 64900))\nhouses_2013['category'] = houses_2013.est_yearly_cost.apply(lambda x: classify_house(x, 62300))\nhouses_2017['category'] = houses_2017.est_yearly_cost.apply(lambda x: classify_house(x, 68000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,6))\nhouses_2017.category.value_counts()[['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']].plot.bar(rot = 0)\nplt.title('Number of Single-Family Homes by Category, 2009');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's explore a couple of types of plots we can use to display our findings. First, let's look at a side-by-side bar chart. Here is an example DataFrame to demonstrate the pieces we need."},{"metadata":{"trusted":true},"cell_type":"code","source":"chess_players = pd.DataFrame({'player': ['Magnus Carlsen', 'Fabiano Caruana', 'Ding Liren'],\n                       'wins': [962, 793,414],\n                        'draws': [930,821,575],\n                       'losses': [334,459,186]})\nchess_players= chess_players.set_index('player')\nchess_players","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (7,5))\nchess_players.plot.bar(ax = ax, edgecolor = 'black', lw = 1.5, rot = 0, width = 0.8)\nplt.title('Top 3 Chess Players by ELO', fontweight = 'bold')\nplt.xlabel('')\nax.legend(bbox_to_anchor=(1, 0.6));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What do we need to pull this off? A dataframe, indexed by the category with a column per year containing the count for that year."},{"metadata":{},"cell_type":"markdown","source":"First, we should combine our three DataFrames into one, using the pandas `concat` function. Start by adding a column to each DataFrame to record the year."},{"metadata":{"trusted":true},"cell_type":"code","source":"houses_2009['year'] = 2009\nhouses_2013['year'] = 2013\nhouses_2017['year'] = 2017","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To concatenate, we pass a list containing the DataFrames we want to combine to the function `pd.concat()`. "},{"metadata":{"trusted":false},"cell_type":"code","source":"houses = pd.concat([houses_2009, houses_2013, houses_2017])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"houses.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need: A DataFrame with 5 rows (categories) and 3 columns (years).\n\n**Exercise:** Group the `houses` DataFrame by category and by year and then count the number of homes per group. Save the result as a DataFrame called `category_count`."},{"metadata":{"trusted":false},"cell_type":"code","source":"category_count = houses.groupby(['category', 'year']).APN.count().reset_index()\ncategory_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is close to what we need except that here all of the years are contained in one column; whereas, we need to have one column per year.\n\nTo show how we can accomplish this, let's first get our chess players DataFrame in the same format as our category_count DataFrame."},{"metadata":{"trusted":false},"cell_type":"code","source":"melted_chess = chess_players.reset_index().melt(id_vars=['player'], var_name = 'outcome')\nmelted_chess","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get `melted_chess` back to the correct form, we can use the `.pivot()` method. To use this method, we have to specify which column will become our index, which column we want to split into our new columns, and which column will be used to assign values."},{"metadata":{"trusted":false},"cell_type":"code","source":"melted_chess.pivot(index='player', columns='outcome', values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Use `.pivot` to get `category_count` into the right form to create a bar plot. Save the result back to `pivot_df`."},{"metadata":{"trusted":false},"cell_type":"code","source":"pivot_df = category_count.pivot(index = 'category', columns = 'year', values = 'APN')\npivot_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can reorder our DataFrame using `.loc`:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pivot_df = pivot_df.loc[['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a bar chart showing the number of single-family homes by affordability category for 2009, 2013, and 2017."},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,6))\npivot_df.plot.bar(ax = ax, edgecolor = 'black', lw = 1.5, rot = 0, width = 0.8)\nplt.title('Number of Single-Family Homes by Category', fontweight = 'bold')\nplt.xlabel('')\nplt.ylabel('Number of Homes')\nax.legend(bbox_to_anchor=(1, 0.6));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Side-by-side bar charts are one option. An different way to display this data is to use a stacked bar chart."},{"metadata":{"trusted":false},"cell_type":"code","source":"chess_players","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8,6))\nchess_players.plot.bar(stacked=True, edgecolor = 'black', lw = 1.5, \n                       rot = 0, ax = ax, width = 0.75,title = 'Top 3 Chess Players by ELO')\nplt.xlabel('')\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(1, 0.6));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make this chart easier to read, we can add annotations to each block.\n\nTo do this, we need to calculate the cumulative sum (height) for each chess player. The numpy method `.cumsum` does this for us."},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (8,6))\nchess_players.plot.bar(stacked=True, edgecolor = 'black', lw = 1.5, \n                       rot = 0, ax = ax, width = 0.75,title = 'Top 3 Chess Players by ELO')\nplt.xlabel('')\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(1, 0.6))\n\nrows = chess_players.iterrows()\nfor i in range(3):\n    values = next(rows)[1]\n    heights = np.array([0] + list(values.cumsum()[:-1])) + values/2\n    for height, value in zip(heights,values):\n        plt.text(x = i, y = height, s = f'{value:,}', color = 'white', ha = 'center', va = 'center', fontweight = 'bold');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Goal:** Create a stacked bar chart showing the number of homes by category split by year.\n\n**What we need:** a DataFrame with 3 rows (years) and 5 columns (categories).\n\n**Exercise:** By pivoting the `category_count` DataFrame, create one called `pivot_df` which meets the above requirements. "},{"metadata":{"trusted":false},"cell_type":"code","source":"pivot_df = category_count.pivot(index='year', columns='category', values='APN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a stacked bar chart showing the number of homes by category with year on the x-axis."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (10,7))\npivot_df.plot.bar(stacked=True, ax = ax, rot = 0, width = 0.75, edgecolor = 'black',lw=1.5)\nplt.title('Davidson County Affordable Single-Family Homes Profile', fontweight = 'bold', fontsize = 14)\nax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\nplt.yticks(fontsize = 12)\nplt.ylabel('Number of Homes', fontsize = 14)\nplt.xticks(fontsize = 14, fontweight = 'bold')\nplt.xlabel('')\n\nrows = pivot_df.iterrows()\nfor i in range(3):\n    values = next(rows)[1]\n    heights = np.array([0] + list(values.cumsum()[:-1])) + values/2\n    for height, value in zip(heights,values):\n        plt.text(x = i, y = height, s = f'{value:,}', color = 'white', ha = 'center', va = 'center', fontweight = 'bold')\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles[::-1], \n              ['More Than 120% of AMI', 'At Least 120% of AMI', 'At Least 90% of AMI', 'At Least 60% of AMI', 'At Least 30% of AMI'], \n              bbox_to_anchor=(1, 0.6), title = 'Not Cost-Burderning to\\nHouseholds Making', title_fontsize = 12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create an interactive plot allowing the user to see the affordable housing profile for a chosen district."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"@interact(district = range(1,36))\ndef make_plot(district):\n    data = houses.loc[houses.CouncilDistrict == district]\n    \n    count_by_category = data.groupby(['year', 'category']).APN.count().reset_index()\n    \n    pivot_df = count_by_category.pivot(index='year', columns='category', values='APN').fillna(0)\n    pivot_df = pivot_df.loc[:,['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']]\n    \n    fig,ax = plt.subplots(figsize = (10,7))\n    pivot_df.plot.bar(stacked=True, ax = ax, rot = 0, width = 0.75, edgecolor = 'black', lw = 1.5)\n    plt.title('Affordable Housing Profile, District ' + str(district), fontweight = 'bold', fontsize = 14)\n    \n    ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n    plt.yticks(fontsize = 12)\n    plt.ylabel('Number of Homes', fontsize = 14)\n    plt.xticks(fontsize = 14, fontweight = 'bold')\n    plt.xlabel('')\n    \n    def check_height(value):\n        if value >= pivot_df.sum(axis = 1).max() * 0.03:\n            return f'{int(value):,}'\n        return ''\n    \n    rows = pivot_df.iterrows()\n    for i in range(3):\n        values = next(rows)[1]\n        heights = np.array([0] + list(values.cumsum()[:-1])) + values/2\n        for height, value in zip(heights,values):\n            plt.text(x = i, y = height, s = check_height(value), color = 'white', ha = 'center', va = 'center', fontweight = 'bold')\n    handles, labels = ax.get_legend_handles_labels()\n    ax.legend(handles[::-1], \n              ['More Than 120% of AMI', 'At Least 120% of AMI', 'At Least 90% of AMI', 'At Least 60% of AMI', 'At Least 30% of AMI'], \n              bbox_to_anchor=(1, 0.9), title = 'Not Cost-Burderning to\\nHouseholds Making', title_fontsize = 12)\n    \n    cd = council_districts[['district', 'geometry']]\n    \n    cd.loc[:,'chosen_district'] = 0\n    cd.loc[cd.district == district, 'chosen_district'] = 1\n    \n    mini_map = plt.axes([.9, .25, .25, .25]) #[left, bottom, width, height]\n    cd.plot(column = 'chosen_district', ax = mini_map, legend = False, edgecolor = 'black', cmap = 'binary')\n    plt.axis('off')\n    plt.title('District ' + str(district)); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Changes by District"},{"metadata":{"trusted":false},"cell_type":"code","source":"overall_pct_change = 100*(houses.loc[houses.year == 2017].TOTALAPPR.median() - houses.loc[houses.year==2013].TOTALAPPR.median()) / houses.loc[houses.year == 2013].TOTALAPPR.median()\noverall_pct_change","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr = houses.groupby(['CouncilDistrict','year']).TOTALAPPR.median().reset_index()\nmedian_appr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr = median_appr.pivot(index = 'CouncilDistrict', columns='year', values='TOTALAPPR')\nmedian_appr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr['pct_change'] = 100*(median_appr[2017] - median_appr[2013]) / median_appr[2013]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"median_appr = median_appr.reset_index()\nmedian_appr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from matplotlib import collections  as mc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines = [[(x,y),(x,overall_pct_change)] for x,y in zip(range(1,36), median_appr['pct_change'])]\n\nfig, ax = plt.subplots()\nmedian_appr.plot.scatter(x = 'CouncilDistrict', y = 'pct_change', figsize = (14,6), ax = ax, s=75)\nax.set_xticks(list(range(1,36)))\nax.set_ylim(0,140)\nplt.grid(axis = 'both', linestyle = '--', alpha = 0.5, lw = 2)\nplt.axhline(y=overall_pct_change, color='r', linestyle='--', lw = 1)\nlc = mc.LineCollection(lines, linewidths=2)\nax.add_collection(lc)\n\nplt.title('Percent Change in Median Appraisal Value, 2013 - 2017', fontweight = 'bold', fontsize = 14)\nplt.xlabel('Council District', fontsize = 14)\nplt.ylabel('Percent Change (%)', fontsize = 14)\nplt.xticks(fontsize = 12, fontweight = 'bold')\nplt.yticks(fontsize = 14)\n\nax.annotate(\"Percent Change for\\nDavidson County\\n(\" + \"{:.1f}\".format(overall_pct_change)+ \"%)\", xy=(36, overall_pct_change), \n            xytext=(33, 90), fontsize = 12, ha = 'center', va = 'center', color = 'red', fontweight = \"bold\",\n            arrowprops=dict(arrowstyle=\"->\", lw = 2))\nax.annotate(\"District 5\\n(\" + \"{:.1f}\".format(median_appr['pct_change'].max())+ \"%)\", xy=(5.5, median_appr['pct_change'].max()-1), \n            xytext=(9, 120), fontsize = 12, ha = 'center', va = 'center', color = 'red', fontweight = \"bold\",\n            arrowprops=dict(arrowstyle=\"->\", lw = 2));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exercise:** Create a chart similar to the one above showing median appraisal value per square foot of finished area."},{"metadata":{"trusted":false},"cell_type":"code","source":"houses_2017['per_sf'] = houses_2017.TOTALAPPR / houses_2017.FinishedArea\noverall_per_sf = houses_2017.per_sf.median()\nper_sf = houses_2017.groupby('CouncilDistrict').per_sf.median().reset_index()\nper_sf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lines = [[(x,y),(x,overall_per_sf)] for x,y in zip(range(1,36), per_sf['per_sf'])]\n\nfig, ax = plt.subplots()\nper_sf.plot.scatter(x = 'CouncilDistrict', y = 'per_sf', figsize = (14,6), ax = ax, s=75)\nax.set_xticks(list(range(1,36)))\n#ax.set_ylim(0,140)\nplt.grid(axis = 'both', linestyle = '--', alpha = 0.5, lw = 2)\nplt.axhline(y=overall_per_sf, color='r', linestyle='-', lw = 1)\nlc = mc.LineCollection(lines, linewidths=2)\nax.add_collection(lc)\n\nplt.title('Median Appraisal Value per Square Foot, 2017', fontweight = 'bold', fontsize = 14)\nplt.xlabel('Council District', fontsize = 14)\nplt.ylabel('Appraisal Value per Square Foot ($)', fontsize = 14)\nplt.xticks(fontsize = 12, fontweight = 'bold')\nplt.yticks(fontsize = 14)\nplt.ylim(0,330)\n\nax.annotate(\"Median for\\nDavidson County\\n(\" + \"${:.2f}\".format(overall_per_sf)+ \")\", xy=(0.5, overall_per_sf), \n            xytext=(4, 240), fontsize = 12, ha = 'center', va = 'center', color = 'red', fontweight = 'bold',\n            arrowprops=dict(arrowstyle=\"->\", lw = 2))\nax.annotate(\"District 19\\n(\" + \"${:.2f}\".format(per_sf.per_sf.max())+ \")\", xy=(19.5, per_sf.per_sf.max() - 1), \n            xytext=(22, 275), fontsize = 12, ha = 'center', va = 'center', color = 'red', fontweight = 'bold',\n            arrowprops=dict(arrowstyle=\"->\", lw = 2));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at Newly-built Homes\n\nLet's see what the picture looks like for homes that were built between 2013 and 2017. To do this, we can merge the 2013 and 2017 DataFrames"},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built = houses_2017.loc[(~ houses_2017.AddressFullAddress.isin(houses_2013.AddressFullAddress)) | \n                             (~ houses_2017.AddressFullAddress.isin(houses_2009.AddressFullAddress))]\nnewly_built.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built.loc[newly_built.category == 'AFF_1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built = newly_built.loc[newly_built.IMPR >= 50000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built.category.value_counts().loc[['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built.category.value_counts(normalize = True).loc[['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"newly_built.loc[newly_built.TOTALAPPR < 1000000].TOTALAPPR.plot.hist(bins = 40, figsize = (10,6), alpha = 0.4, density = True, color='blue', label = 'newly_built', legend = True, title = 'Distribution of Appraisal Values, 2017')\nhouses_2017.loc[(houses_2017.TOTALAPPR < 1000000) & (houses_2017.IMPR >= 50000)].TOTALAPPR.plot.hist(bins = 40, figsize = (10,6), alpha = 0.4, density = True, color='red', label = 'overall', legend = True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"houses_2017_trimmed = houses_2017.loc[houses_2017.IMPR > 50000]\nhouses_2017_trimmed['newly_built'] = (~ houses_2017.AddressFullAddress.isin(houses_2009.AddressFullAddress)) |(~ houses_2017.AddressFullAddress.isin(houses_2013.AddressFullAddress))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 7: Seaborn"},{"metadata":{},"cell_type":"markdown","source":"Seaborn is a visualization library built on top of matplotlib."},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seaborn gives us options to compare home appraisal values across districts or across years. For example, we can use a box plot."},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.boxplot(data = houses_2017.loc[houses_2017.CouncilDistrict.isin([1,2,3,4])], \n            x = 'CouncilDistrict', \n            y = 'TOTALAPPR')\nplt.title('Home Appriasal Values, 2017')\nplt.ylim(0, 1000000);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another option is to use a violin plot, which includes a density estimation."},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.violinplot(data = houses_2017.loc[houses_2017.CouncilDistrict.isin([1,2,3,4])], x = 'CouncilDistrict', \n               y = 'TOTALAPPR')\nplt.title('Home Appraisal Values, 2017')\nplt.ylim(0, 1000000);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.boxplot(data = houses, x = 'year', y = 'TOTALAPPR')\nplt.title('Home Appraisal Values')\nplt.ylim(0, 1000000);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.violinplot(data = houses, x = 'year', y = 'TOTALAPPR')\nplt.title('Home Appraisal Values')\nplt.ylim(0, 1000000);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we want to dynamically change the maximum value based on the district? We can use the numpy library to help us. Specifically, the numpy `percentile` function can be used to set a maximum value.\n\nFor example, to find the appraisal value for which 90% of homes are appraised below, use `np.percentile` and specify 90 as the percentile we wish to find."},{"metadata":{"trusted":false},"cell_type":"code","source":"np.percentile(houses.loc[houses.CouncilDistrict == 34, 'TOTALAPPR'], 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(district = range(1,36), plot_type = ['box', 'violin'])\ndef plot_dist(district, plot_type):\n    fig = plt.figure(figsize = (10,6))\n    if plot_type == 'box':\n        sns.boxplot(data = houses.loc[houses.CouncilDistrict == district], x = 'year', y = 'TOTALAPPR')\n    if plot_type == 'violin':\n        sns.violinplot(data = houses.loc[houses.CouncilDistrict == district], x = 'year', y = 'TOTALAPPR')\n    ymax = np.percentile(houses.loc[(houses.CouncilDistrict == district) & (houses.year == 2017), 'TOTALAPPR'], 99.9)\n    plt.ylim(0, ymax)\n    plt.title('Total Appraised Value, District ' + str(district));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cd = council_districts[['district', 'geometry']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(district = range(1,36), plot_type = ['box', 'violin'])\ndef plot_dist(district, plot_type):\n    fig = plt.figure(figsize = (10,6))\n    if plot_type == 'box':\n        sns.boxplot(data = houses.loc[houses.CouncilDistrict == district], x = 'year', y = 'TOTALAPPR')\n    if plot_type == 'violin':\n        sns.violinplot(data = houses.loc[houses.CouncilDistrict == district], x = 'year', y = 'TOTALAPPR')\n    ymax = np.percentile(houses.loc[(houses.CouncilDistrict == district) & (houses.year == 2017), 'TOTALAPPR'], 99.9)\n    plt.ylim(0, ymax)\n    plt.title('Total Appraised Value, District ' + str(district))\n    \n    cd['chosen_district'] = 0\n    cd.loc[cd.district == district, 'chosen_district'] = 1\n    \n    mini_map = plt.axes([.85, .3, .4, .4]) #[left, bottom, width, height]\n    cd.plot(column = 'chosen_district', ax = mini_map, legend = False, edgecolor = 'black', cmap = 'binary')\n    plt.axis('off')\n    plt.title('District ' + str(district));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seaborn also provides distplots, which can do histograms or kernel density estimates, which are essentially smoothed histograms."},{"metadata":{"trusted":false},"cell_type":"code","source":"df = houses.loc[houses.CouncilDistrict == 20]\n\ntarget_0 = df.loc[df.year == 2009]\ntarget_1 = df.loc[df.year == 2013]\ntarget_2 = df.loc[df.year == 2017]\n\nsns.distplot(target_0[['TOTALAPPR']], hist=False, label = '2009')\nsns.distplot(target_1[['TOTALAPPR']], hist=False, label = '2013')\ng = sns.distplot(target_2[['TOTALAPPR']], hist=False, label = '2017')\n\ng.set(xlim=(0, 500000));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = houses.loc[houses.CouncilDistrict == 20]\n\ntarget_0 = df.loc[df.year == 2009]\ntarget_1 = df.loc[df.year == 2013]\ntarget_2 = df.loc[df.year == 2017]\n\nsns.distplot(target_0[['TOTALAPPR']], hist=True, label = '2009')\nsns.distplot(target_1[['TOTALAPPR']], hist=True, label = '2013')\ng = sns.distplot(target_2[['TOTALAPPR']], hist=True, label = '2017')\n\ng.set(xlim=(0, 500000));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(district = range(1,36))\ndef make_dist_plot(district):\n    plt.figure(figsize = (10,6))\n    \n    df = houses.loc[houses.CouncilDistrict == district]\n\n    target_0 = df.loc[df.year == 2009]\n    target_1 = df.loc[df.year == 2013]\n    target_2 = df.loc[df.year == 2017]\n\n    sns.distplot(target_0[['TOTALAPPR']], hist=False, label = '2009', kde_kws={'lw': 2.5})\n    sns.distplot(target_1[['TOTALAPPR']], hist=False, label = '2013', kde_kws={'lw': 2.5})\n    g = sns.distplot(target_2[['TOTALAPPR']], hist=False, label = '2017', kde_kws={'lw': 2.5}, color = 'purple')\n\n    xmax = np.percentile(houses.loc[(houses.CouncilDistrict == district) & (houses.year == 2017), 'TOTALAPPR'], 95)\n\n    g.set(xlim=(0, xmax))\n    g.set(yticks = [])\n    g.set(title=\"Distribution of Appraisal Values, District \" + str(district));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 8: Plotly"},{"metadata":{},"cell_type":"markdown","source":"`plotly` is another visualization library which allows for more dynamic, interactive graphics. The `plotly express` module makes it easy to work with pandas dataframes to quickly produce dynamic, interactive plots."},{"metadata":{"trusted":false},"cell_type":"code","source":"import plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"chess_players","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotly express requires our data to be \"tidy\". This means only one \"observation\" per row. Currently, our `chess_players` DataFrame is not tidy, because we should have only one type of observation per row. To tidy it, we can use the `.melt()` method."},{"metadata":{"trusted":false},"cell_type":"code","source":"melted_chess = chess_players.reset_index().melt(id_vars=['player'], var_name = 'outcome')\nmelted_chess","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = px.bar(melted_chess, x='player', y='value', color = 'outcome', \n             width = 800, height = 500,\n            category_orders = {'outcome' : ['wins', 'losses', 'draws']})\nfig.update_layout(title_text = 'Top Rated Chess Players', title_font_size = 24)\nfig.update_yaxes(title_text = 'Number of Games', title_font_size = 20, tickfont_size = 14,)\nfig.update_xaxes(title_text = '', tickfont_size = 18)\nfig.update_layout(legend_traceorder = 'reversed')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"category_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"category_count.year = category_count.year.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(district = range(1, 36))\ndef make_plot(district):\n    df = houses.loc[houses.CouncilDistrict == district].groupby(['category', 'year']).APN.count().reset_index().rename(columns = {'APN' : 'count'})\n    #df.year = df.year.astype('category')\n    fig = px.bar(df, x='year', y='count', color = 'category', width = 800, height = 500,\n                category_orders = {'category' : ['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']})\n    fig.update_yaxes(title_text = 'Number of Homes', title_font_size = 18)\n    fig.update_xaxes(title_text = '', tick0=2009, dtick=4, tickfont_size = 18)\n    fig.update_layout(title_text = 'Affordable Housing Profile, District ' + str(district), title_font_size = 20)\n    fig.update_layout(legend_traceorder = 'reversed')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"district_counts = houses.groupby(['year', 'CouncilDistrict', 'category']).APN.count().reset_index().rename(columns = {'APN' : 'num_homes'})\ndistrict_counts = district_counts.loc[district_counts.CouncilDistrict.isin(list(range(1,36)))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(year = [2009, 2013, 2017])\ndef make_plot(year):\n    df = district_counts.loc[district_counts.year == year]\n    fig = px.bar(df, x='CouncilDistrict', y='num_homes', color = 'category', width = 900, height = 500,\n                category_orders = {'category' : ['AFF_1', 'AFF_2', 'WF_1', 'WF_2', 'AWF']})\n    fig.update_yaxes(title_text = 'Number of Homes', title_font_size = 18, range = [0,8300])\n    fig.update_xaxes(title_text = 'District', tick0=1, dtick=1, tickfont_size = 14, tickangle = 0)\n    fig.update_layout(title_text = 'Davidson County Affordable Housing Profile by District, ' + str(year), title_font_size = 20)\n    fig.update_layout(legend_traceorder = 'reversed')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@interact(district = range(1,36))\ndef make_plotly(district):\n    df = houses.loc[houses.CouncilDistrict == district]\n    ymax = np.percentile(df.TOTALAPPR, 99.9)\n    \n    fig = px.box(df, x=\"year\", y=\"TOTALAPPR\", width = 800, height = 500)\n    fig.update_yaxes(range=[0,ymax], title_text = 'Appraised Value', title_font_size = 18)\n    fig.update_xaxes(title_text = '', tickfont_size = 18)\n    fig.update_layout(title_text = 'Appraised Values, District ' + str(district), title_font_size = 20)\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@interact(district = range(1,36))\ndef make_plotly(district):\n    df = houses.loc[houses.CouncilDistrict == district]\n    ymax = np.percentile(df.TOTALAPPR, 99.9)\n    \n    fig = px.violin(df, x=\"year\", y=\"TOTALAPPR\", width = 800, height = 500, box = True)\n    fig.update_yaxes(range=[0,ymax], title_text = 'Appraised Value', title_font_size = 18)\n    fig.update_xaxes(title_text = '', tickfont_size = 18)\n    fig.update_layout(title_text = 'Appraised Values, District ' + str(district), title_font_size = 20)\n\n    fig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}